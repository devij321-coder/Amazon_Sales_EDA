{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploratory data Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devij321-coder/Amazon_Sales_EDA/blob/main/Exploratory_data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOvht7vqQGdR"
      },
      "source": [
        "AMAZON PRIME TV SHOWS AND MOVIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhA_0CQOTDQy"
      },
      "source": [
        "title.*csv*\n",
        "\n",
        "load title.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dataset:('titles.csv');"
      ],
      "metadata": {
        "id": "Aw6-z0dfRA5f"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEfC0QszTKX_"
      },
      "source": [
        "\n",
        "![alt text](https://moriohcdn.b-cdn.net/ff3cc511fb.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB_j6LtTTO5j"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hg00soETQ3z"
      },
      "source": [
        "**What is Exploratory Data Analysis ?**\n",
        "\n",
        "Exploratory Data Analysis or (EDA) is understanding the data sets by summarizing their main characteristics often plotting them visually. This step is very important especially when we arrive at modeling the data in order to apply Machine learning. Plotting in EDA consists of Histograms, Box plot, Scatter plot and many more. It often takes much time to explore the data. Through the process of EDA, we can ask to define the problem statement or definition on our data set which is very important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfelutoyTS25"
      },
      "source": [
        "**How to perform Exploratory Data Analysis ?**\n",
        "\n",
        "This is one such question that everyone is keen on knowing the answer. Well, the answer is it depends on the data set that you are working. There is no one method or common methods in order to perform EDA, whereas in this tutorial you can understand some common methods and plots that would be used in the EDA process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3VfNkBBw15s"
      },
      "source": [
        "**What data are we exploring today ?**\n",
        "\n",
        "\n",
        "\n",
        "Since I am a huge fan of cars, I got a very beautiful data-set of cars from Kaggle. The data-set can be downloaded from [here](https://www.kaggle.com/CooperUnion/cardataset). To give a piece of brief information about the data set this data contains more of 10, 000 rows and more than 10 columns which contains features of the car such as Engine Fuel Type, Engine HP, Transmission Type, highway MPG, city MPG and many more. So in this tutorial, we will explore the data and make it ready for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQDO4JCqTThV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPSqz1wzTXvz"
      },
      "source": [
        "## 1. Importing the required libraries for EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eLMx1Ebwa92"
      },
      "source": [
        "Below are the libraries that are used in order to perform EDA (Exploratory data analysis) in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGyDovL2QDLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "outputId": "17919d42-9710-48a9-d6d9-31f036b9f2f1"
      },
      "source": [
        "from pickle import OBJ\n",
        "from ast import Str\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns                       #visualisation\n",
        "import matplotlib.pyplot as plt             #visualisation\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "titles = \"datasets\" # now EDA refers to the same datasets\n",
        "titles.str.head(5)\n",
        "dataframe = \"df\"\n",
        "print(dataframe)\n",
        "Day = str(6)\n",
        "year = str(2025)\n",
        "month = str(5)\n",
        "Datetime = str(Day + \"-\" + month + \"-\" + year)\n",
        "print(Datetime)\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2887723273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"datasets\"\u001b[0m \u001b[0;31m# now EDA refers to the same datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"df\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y3Z2DbKTfJt"
      },
      "source": [
        "## 2. Loading the data into the data frame.\n",
        "Load data into \"Titles\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import LambdaType\n",
        "from __future__ import generator_stop\n",
        "from inspect import getinnerframes\n",
        "load_dataset = ('titles.csv');\n",
        "head:(5)\n",
        "tail:(5)\n",
        "\n",
        "DATA CLEANING:\n",
        "\n",
        "print(\"nullcount\")\n",
        "str: titles\n",
        "print(titles)\n",
        "\n",
        "# How do I convert released date to dateformate in EDA:\n",
        "\n",
        "date_time_str = '2018-06-29'\n",
        "Str[\"date\"] = 'OBJ_datetime'(str[\"date_str\"], format=\"%Y-%m-%d\")\n",
        "print(str[\"datetime\"])\n",
        "\n",
        "HOW DO I COUNT MOVIES AND TV SHOWS IN THE DATASET:\n",
        "\n",
        "dataframe(\"movies\"),Count_Values:('movies_type'())\n",
        "dataframe(\"shows\"),Count_Values:('show_type'())\n",
        "\n",
        "HOW DO I GET TOP 10 geners\n",
        "\n",
        "dataframe: object='value_counts'('geners'),str('Top10_geners')\n",
        "\n",
        "HOW DO I COUNT HOW MANY TITLES WERE RELEASED EACH YEAR\n",
        "\n",
        "count_values:str ('each_year')\n",
        "count_object:str('each_year')\n",
        "\n",
        "HOW DO I FOUND MOST FREQUENT Doctors:\n",
        "\n",
        "count_values: str(\"Doctors\")\n",
        "count_object: str(\"Doctors\")\n",
        "\n",
        "HOW CAN I ANALYZE KEY WORDS LIKE 'LOVE', 'WAR' IN TITLE:\n",
        "\n",
        "LabelType: \"Title\"\n",
        "DataFrameGroupBy: \"LOVE\"\n",
        "DataFrameGroupBy: \"WAR\"\n",
        "\n",
        "HOW CAN I MAKE WORD CLOUD FROM TITLE:\n",
        "\n",
        "DATASET=\"title\"\n",
        "GroupBy=\"cloud\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ivGGNYfJV5iZ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko5zGJFCySaz"
      },
      "source": [
        "Loading the data into the pandas data frame is certainly one of the most important steps in EDA, as we can see that the value from the data set is comma-separated. So all we have to do is to just read the CSV into a data frame and pandas data frame does the job for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgzUzD61IM8h"
      },
      "source": [
        "To get or load the dataset into the notebook, all I did was one trivial step. In Google Colab at the left-hand side of the notebook, you will find a > (greater than symbol). When you click that you will find a tab with three options, you just have to select Files. Then you can easily upload your file with the help of the Upload option. No need to mount to the google drive or use any specific libraries just upload the data set and your job is done. One thing to remember in this step is that uploaded files will get deleted when this runtime is recycled. This is how I got the data set into the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm-9dzdTRKpe"
      },
      "source": [
        "df.tail(5)                        # To display the botton 5 rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQnr4SPzaL5"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAmC369yTpMF"
      },
      "source": [
        "## 3. Checking the types of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ESKxikIzA1d"
      },
      "source": [
        "Here we check for the datatypes because sometimes the MSRP or the price of the car would be stored as a string, if in that case, we have to convert that string to the integer data only then we can plot the data via a graph. Here, in this case, the data is already in integer format so nothing to worry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRJyQAezdX8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbKQ0noRptD",
        "outputId": "a4616ce4-3501-4e1d-c75e-c6fc1fe5ebea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "collapsed": true
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1008660192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoHuBhXxT5E9"
      },
      "source": [
        "## 4. Dropping irrelevant columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3cy877Mze4H"
      },
      "source": [
        "This step is certainly needed in every EDA because sometimes there would be many columns that we never use in such cases dropping is the only solution. In this case, the columns such as Engine Fuel Type, Market Category, Vehicle style, Popularity, Number of doors, Vehicle Size doesn't make any sense to me so I just dropped for this instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvSkK8swTr9H"
      },
      "source": [
        "df = df.drop(['Engine Fuel Type', 'Market Category', 'Vehicle Style', 'Popularity', 'Number of Doors', 'Vehicle Size'], axis=1)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20OeQBpWz89v"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tcGiOmV0afN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiW7x_O4WIDX"
      },
      "source": [
        "## 6. Dropping the duplicate rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LpR5NW70hXm"
      },
      "source": [
        "This is often a handy thing to do because a huge data set as in this case contains more than 10, 000 rows often have some duplicate data which might be disturbing, so here I remove all the duplicate value from the data-set. For example prior to removing I had 11914 rows of data but after removing the duplicates 10925 data meaning that I had 989 of duplicate data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chhNvMFCIzqI"
      },
      "source": [
        "Now let us remove the duplicate data because it's ok to remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuobmetTV820"
      },
      "source": [
        "df.count()      # Used to count the number of rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MJKjbzHI40K"
      },
      "source": [
        "So seen above there are 11914 rows and we are removing 989 rows of duplicate data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiOsEF6WVTSj",
        "collapsed": true
      },
      "source": [
        "df = df.drop_duplicates()\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gMM4lb0Vzor",
        "outputId": "99c814c4-a306-4cc9-a2e4-c68679ac08d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2255720674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCLUdZOQ1PDP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkXUQtyQW3Dy"
      },
      "source": [
        "## 7. Dropping the missing or null values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWJqTVxTJQnO"
      },
      "source": [
        "This is the reason in the above step while counting both Cylinders and Horsepower (HP) had 10856 and 10895 over 10925 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t7L9l2mJSoX"
      },
      "source": [
        "Now we have removed all the rows which contain the Null or N/A values (Cylinders and Horsepower (HP))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-DmX1O4Wtox"
      },
      "source": [
        "print(df.isnull().sum())   # After dropping the values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk8RAHqQJVJK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqFPRda8eEp_"
      },
      "source": [
        "## 9. Plot different features against one another (scatter), against frequency (histogram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-W6Q9-hJosZ"
      },
      "source": [
        "### Histogram\n",
        "\n",
        "Histogram refers to the frequency of occurrence of variables in an interval. In this case, there are mainly 10 different types of car manufacturing companies, but it is often important to know who has the most number of cars. To do this histogram is one of the trivial solutions which lets us know the total number of car manufactured by a different company."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAnd4DSyeHDb"
      },
      "source": [
        "df.Make.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
        "plt.title(\"Number of cars by make\")\n",
        "plt.ylabel('Number of cars')\n",
        "plt.xlabel('Make');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c37WtYYWJuAQ"
      },
      "source": [
        "### Heat Maps\n",
        "\n",
        "Heat Maps is a type of plot which is necessary when we need to find the dependent variables. One of the best way to find the relationship between the features can be done using heat maps. In the below heat map we know that the price feature depends mainly on the Engine Size, Horsepower, and Cylinders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhHfLVTj6nmy",
        "outputId": "0091cea3-7d0e-4b3b-b323-bbceb241ae07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "plt.figure(figsize=(10,5))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQXy8o_gKFS5"
      },
      "source": [
        "**Hence the above are some of the steps involved in Exploratory data analysis, these are some general steps that you must follow in order to perform EDA. There are many more yet to come but for now, this is more than enough idea as to how to perform a good EDA given any data sets. Stay tuned for more updates.**\n",
        "\n",
        "## Thank you."
      ]
    }
  ]
}